{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CMTVt2KOdN3s",
    "outputId": "b478d023-64b7-4b71-91a1-dd852db14dbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
      "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.4)\n",
      "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.10/dist-packages (0.2.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.17 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.3.19)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.8.0)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain-openai) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain-openai) (0.1.143)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain-openai) (24.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain-openai) (9.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.9.11)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.17->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.17->langchain-openai) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.17->langchain-openai) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4 openai langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6WmyBa9dd8qj"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F_Jseg7UeHPa"
   },
   "outputs": [],
   "source": [
    "def extract_text_from_url(url):\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "      soup = BeautifulSoup(response.text, 'html.parser')\n",
    "      for script_or_style in soup([\"script\", \"style\"]):\n",
    "        script_or_style.decompose()\n",
    "      texto = soup.get_text(separator=' ')\n",
    "      # Limpar texto\n",
    "      linhas = (linha.strip() for linha in texto.splitlines())\n",
    "      partes = (parte.strip() for linha in linhas for parte in linha.split(\"  \"))\n",
    "      texto_limpo = '\\n'.join(parte for parte in partes if parte)\n",
    "      return texto_limpo\n",
    "    else:\n",
    "      print(f\"Failed to fetch URL. Status code: {response.status_code}\")\n",
    "      return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 553
    },
    "id": "4UCkDwSceZ3x",
    "outputId": "d56d8ba6-a39b-4c21-db96-fc0e609e9b95"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Azure Open AI in VNet - DEV Community\\nSkip to content\\nNavigation menu\\nSearch\\nPowered by\\nSearch\\nAlgolia\\nSearch\\nLog in\\nCreate account\\nDEV Community\\nClose\\nAdd reaction\\nLike\\nUnicorn\\nExploding Head\\nRaised Hands\\nFire\\nJump to Comments\\nSave\\nMore...\\nCopy link\\nCopy link\\nCopied to Clipboard\\nShare to X\\nShare to LinkedIn\\nShare to Facebook\\nShare to Mastodon\\nReport Abuse\\nKenichiro Nakamura\\nPosted on\\nOct 12, 2023\\nAzure Open AI in VNet\\n# azure\\n# openai\\n# security\\nGPT models are hosted in multiple service vendor at the moment, and Microsoft Azure is one of them.\\nEven though the models themselves are the same, there are many differences including:\\ncost\\nfunctionalities\\ntype of models and versions\\ngeo location\\nsecurity\\nsupport\\netc.\\nOne of the most important aspects when we use it in an Enterprise Environment is, of course, security.\\nBy using Azure network security features with Azure Open AI, customers can consume the Open AI service from and within the VNet, therefore no information is flowing in public.\\nSample Deployment\\nAzure Sample repo provides a sample bicep files to deploy Azure Open AI into VNet environment.\\nGitHub: openai-enterprise-iac\\nThe key features the bicep uses are:\\nVNet\\nVNet integration for Web App\\nPrivate Endpoint for Azure Open AI\\nPrivate Endpoint for Cognitive Search\\nPrivate DNS Zone\\nBy using these features, all the outbound traffic from the Web App only routed inside the VNet and all the names are resolved into private IP addresses. Open AI and Cognitive Search shut down the public IP address, thus there is not public interface endpoint available anymore.\\nDeploy\\nThe bicep file will deploy following Azure Resources.\\nLet's deploy and confirm how it works. I create a resource group in East US region for my own test.\\ngit clone https://github.com/Azure-Samples/openai-enterprise-iac\\ncd\\nopenai-enterprise-iac\\naz group create\\n-n\\nopenaitest\\n-l\\neastus\\naz deployment group create\\n-g\\nopenaitest\\n-f\\n. \\\\i nfra \\\\m ain.bicep\\nEnter fullscreen mode\\nExit fullscreen mode\\nOnce I run the commend above, I see the deployment started.\\nWait until the deployment completes.\\nTest\\nLet's see if the deployment was succeeded.\\nAzure Open AI\\nLet's try public access first.\\nI could create a deployment without any issue. But when I try from the Chat playground in my Azure Portal, I see the following error.\\nHow about access via the Web API?\\nFrom an advanced tool of the App Service, I login to Bash session, and first I ping the service URL.\\nI see the private IP address assigned to the Private Endpoint is returend.\\nThen I use curl command to send request to the endpoint.\\nTop comments\\n(0)\\nSubscribe\\nPersonal\\nTrusted User\\nCreate template\\nTemplates let you quickly answer FAQs or store snippets for re-use.\\nSubmit\\nPreview\\nDismiss\\nCode of Conduct\\nâ€¢\\nReport abuse\\nAre you sure you want to hide this comment? It will become hidden in your post, but will still be visible via the comment's\\npermalink .\\nHide child comments as well\\nConfirm\\nFor further actions, you may consider blocking this person and/or\\nreporting abuse\\nRead next\\nSecurity news weekly round-up - 1st November 2024\\nHabdul Hazeez -\\nNov 1\\nMove hardcoded secrets to a Secrets Manager\\nKhai J. Thani -\\nOct 13\\nWhy Every Company Needs Security Checkers in 2025\\nNatasha Ramzan -\\nNov 11\\nHow to Kill Vulnerabilities in Your Node.js App: A Guide to Writing Secure JavaScript Code\\nAivan Carlos Tuquero -\\nNov 10\\nKenichiro Nakamura\\nFollow\\nJoined\\nFeb 3, 2018\\nMore from\\nKenichiro Nakamura\\nAzure ML Prompt flow: Use content safety before sending a request to LLM\\n# azure\\n# promptflow\\n# contentsafety\\nDon't waste time to write README, use readme-ai instead\\n# ai\\n# readme\\n# openai\\nC#: Azure Open AI and Function Calling\\n# azure\\n# openai\\n# functioncalling\\nThank you to our Diamond Sponsor\\nNeon\\nfor supporting our community.\\nDEV Community\\nâ€” A constructive and inclusive social network for software developers. With you every step of your journey.\\nHome\\nDEV++\\nPodcasts\\nVideos\\nTags\\nDEV Help\\nForem Shop\\nAdvertise on DEV\\nDEV Challenges\\nDEV Showcase\\nAbout\\nContact\\nFree Postgres Database\\nGuides\\nSoftware comparisons\\nCode of Conduct\\nPrivacy Policy\\nTerms of use\\nBuilt on\\nForem\\nâ€” the\\nopen source\\nsoftware that powers\\nDEV\\nand other inclusive communities.\\nMade with love and\\nRuby on Rails . DEV Community\\nÂ©\\n2016 - 2024.\\nWe're a place where coders share, stay up-to-date and grow their careers.\\nLog in\\nCreate account\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_text_from_url(\"https://dev.to/kenakamu/azure-open-ai-in-vnet-3alo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8JZyeRSpf67T"
   },
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models.azure import AzureChatOpenAI\n",
    "\n",
    "\n",
    "client = AzureChatOpenAI(\n",
    "  azure_endpoint= \"https://bootcamp-dio-openai.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-08-01-preview\",\n",
    "  api_key= \"AZURE_OPENAI_KEY\",\n",
    "  api_version= \"2024-08-01-preview\",\n",
    "  deployment_name= \"gpt-4o-mini\",\n",
    "  max_retries=0,\n",
    "  max_tokens=500\n",
    ")\n",
    "\n",
    "def translate_article(text, lang):\n",
    "  messages = [\n",
    "      (\"system\", \"VocÃª atua como tradutor de textos\"),\n",
    "      (\"user\", f\"Traduza o {text} para o idioma {lang} e responda em markdown\"),\n",
    "  ]\n",
    "\n",
    "  response = client.invoke(messages)\n",
    "  print(response.content)\n",
    "  return response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "QRBHkzDZii8w",
    "outputId": "ada1e539-284e-4259-8cc5-69a41b57f73e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os modelos GPT estÃ£o hospedados em vÃ¡rios fornecedores de serviÃ§os no momento, e o Microsoft Azure Ã© um deles.\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Os modelos GPT estÃ£o hospedados em vÃ¡rios fornecedores de serviÃ§os no momento, e o Microsoft Azure Ã© um deles.'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_article(\"GPT models are hosted in multiple service vendor at the moment, and Microsoft Azure is one of them.\", \"portuguÃªs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5C_G2st85spa"
   },
   "outputs": [],
   "source": [
    "url = \"https://dev.to/kenakamu/azure-open-ai-in-vnet-3alo\"\n",
    "text = extract_text_from_url(url)\n",
    "\n",
    "translate_article(text[:1000], \"portuguÃªs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "id": "NdRiLNYTjTQ2",
    "outputId": "a8f8624a-3e61-488c-a03e-dc34ac7c9396"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Azure Open AI na VNet\n",
      "\n",
      "Kenichiro Nakamura  \n",
      "Postado em 12 de outubro de 2023\n",
      "\n",
      "Modelos GPT estÃ£o hospedados em vÃ¡rios fornecedores de serviÃ§os no momento, e o Microsoft Azure Ã© um deles. Mesmo que os modelos em si sejam os mesmos, existem muitas diferenÃ§as, incluindo:\n",
      "\n",
      "- custo\n",
      "- funcionalidades\n",
      "- tipo de modelos e versÃµes\n",
      "- localizaÃ§Ã£o geogrÃ¡fica\n",
      "- seguranÃ§a\n",
      "- suporte\n",
      "- etc.\n",
      "\n",
      "Um dos aspectos mais importantes ao usÃ¡-lo em um Ambiente Empresarial Ã©, claro, a seguranÃ§a. Ao utilizar os recursos de seguranÃ§a de rede do Azure com o Azure Open AI, os clientes podem consumir o serviÃ§o Open AI a partir e dentro da VNet, portanto, nenhuma informaÃ§Ã£o estÃ¡ fluindo publicamente.\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'# Azure Open AI na VNet\\n\\nKenichiro Nakamura  \\nPostado em 12 de outubro de 2023\\n\\nModelos GPT estÃ£o hospedados em vÃ¡rios fornecedores de serviÃ§os no momento, e o Microsoft Azure Ã© um deles. Mesmo que os modelos em si sejam os mesmos, existem muitas diferenÃ§as, incluindo:\\n\\n- custo\\n- funcionalidades\\n- tipo de modelos e versÃµes\\n- localizaÃ§Ã£o geogrÃ¡fica\\n- seguranÃ§a\\n- suporte\\n- etc.\\n\\nUm dos aspectos mais importantes ao usÃ¡-lo em um Ambiente Empresarial Ã©, claro, a seguranÃ§a. Ao utilizar os recursos de seguranÃ§a de rede do Azure com o Azure Open AI, os clientes podem consumir o serviÃ§o Open AI a partir e dentro da VNet, portanto, nenhuma informaÃ§Ã£o estÃ¡ fluindo publicamente.'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://dev.to/kenakamu/azure-open-ai-in-vnet-3alo\"\n",
    "text = extract_text_from_url(url)\n",
    "\n",
    "translate_article(text[:1000], \"portuguÃªs\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
